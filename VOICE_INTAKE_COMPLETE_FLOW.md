# ğŸ¤ Voice Intake Feature - Complete Flow Documentation

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Patient   â”‚ â”€â”€â”€> â”‚   Frontend   â”‚ â”€â”€â”€> â”‚    Backend      â”‚ â”€â”€â”€> â”‚   Supabase   â”‚
â”‚   Browser   â”‚      â”‚  (Next.js)   â”‚      â”‚   (FastAPI)     â”‚      â”‚  (Database)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                      â”‚                       â”‚                       â”‚
      â”‚                      â”‚                       â”‚                       â”‚
      â–¼                      â–¼                       â–¼                       â–¼
  Microphone          MediaRecorder           Google Cloud            voice_intake_
   Audio              WebM/Opus               Speech-to-Text           records table
                                              + Gemini AI
```

## ğŸ”„ Complete User Journey

### Step 1: Patient Navigates to Voice Intake
```
Patient Dashboard â†’ Click "Voice Intake" Card
â†“
/patient/voice-intake page loads
â†“
VoiceIntakeForm component renders
```

**Files Involved:**
- `frontend/app/patient/dashboard/page.tsx` - Dashboard with Voice Intake card
- `frontend/app/patient/voice-intake/page.tsx` - Voice intake page
- `frontend/components/voice-intake/voice-intake-form.tsx` - Main form component

### Step 2: Patient Selects Language
```
User sees language dropdown
â†“
Selects language (Hindi, English, Bengali, etc.)
â†“
Language code stored in state (e.g., "hi-IN", "en-IN")
```

**Supported Languages:**
- Hindi (à¤¹à¤¿à¤‚à¤¦à¥€) - `hi-IN`
- English (India) - `en-IN`
- English (US) - `en-US`
- Bengali (à¦¬à¦¾à¦‚à¦²à¦¾) - `bn-IN`
- Telugu (à°¤à±†à°²à±à°—à±) - `te-IN`
- Marathi (à¤®à¤°à¤¾à¤ à¥€) - `mr-IN`
- Tamil (à®¤à®®à®¿à®´à¯) - `ta-IN`
- Gujarati (àª—à«àªœàª°àª¾àª¤à«€) - `gu-IN`
- Kannada (à²•à²¨à³à²¨à²¡) - `kn-IN`
- Malayalam (à´®à´²à´¯à´¾à´³à´‚) - `ml-IN`

### Step 3: Patient Records Audio
```
Click "Start Recording"
â†“
Browser requests microphone permission
â†“
MediaRecorder starts capturing audio
â†“
Audio format: WebM with Opus codec
â†“
Timer starts counting (0:00, 0:01, 0:02...)
â†“
Patient speaks medical history
â†“
Click "Stop Recording"
â†“
MediaRecorder stops, audio chunks combined into Blob
```

**Code Flow:**
```typescript
// frontend/components/voice-intake/voice-intake-form.tsx

startRecording() {
  navigator.mediaDevices.getUserMedia({ audio: true })
  â†’ new MediaRecorder(stream, { mimeType: 'audio/webm;codecs=opus' })
  â†’ mediaRecorder.start()
  â†’ setIsRecording(true)
}

stopRecording() {
  mediaRecorder.stop()
  â†’ audioBlob = new Blob(audioChunks, { type: 'audio/webm' })
  â†’ processAudio(audioBlob)
}
```

### Step 4: Frontend Sends Audio to Backend
```
processAudio(audioBlob)
â†“
Create FormData with:
  - audio: Blob (WebM file)
  - patient_id: UUID
  - language_code: "hi-IN" (or selected language)
â†“
POST /api/voice-intake/process
â†“
Show "Processing your recording..." spinner
```

**HTTP Request:**
```http
POST http://localhost:8000/api/voice-intake/process
Content-Type: multipart/form-data

audio: [Binary WebM data]
patient_id: "123e4567-e89b-12d3-a456-426614174000"
language_code: "hi-IN"
```

### Step 5: Backend Processes Audio (Speech-to-Text)
```
Backend receives audio
â†“
Initialize Google Cloud Speech client
â†“
Configure recognition:
  - encoding: WEBM_OPUS
  - sample_rate: 48000 Hz
  - language_code: "hi-IN"
  - model: "medical_conversation" (only for en-US) or "default"
  - enable_automatic_punctuation: true
â†“
Call speech_client.recognize()
â†“
Get transcript in original language
```

**Code Flow:**
```python
# backend/app/voice_intake.py

@router.post("/process")
async def process_voice_intake(audio, patient_id, language_code):
    # Read audio
    audio_content = await audio.read()
    
    # Configure Google Cloud Speech
    config = speech.RecognitionConfig(
        encoding=speech.RecognitionConfig.AudioEncoding.WEBM_OPUS,
        sample_rate_hertz=48000,
        language_code=language_code,
        enable_automatic_punctuation=True,
        model="medical_conversation" if language_code == 'en-US' else "default",
        use_enhanced=True
    )
    
    # Transcribe
    response = speech_client.recognize(config=config, audio=audio_config)
    transcript = " ".join([result.alternatives[0].transcript for result in response.results])
```

**Example Transcript:**
```
Original (Hindi): "à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® à¤°à¤¾à¤œ à¤¹à¥ˆ, à¤®à¥à¤à¥‡ à¤¬à¥à¤–à¤¾à¤° à¤¹à¥ˆ à¤¤à¥€à¤¨ à¤¦à¤¿à¤¨ à¤¸à¥‡"
```

### Step 6: Backend Extracts Structured Data (Gemini AI)
```
Send transcript to Gemini AI
â†“
Prompt: "Extract patient information and translate to English"
â†“
Gemini analyzes transcript
â†“
Returns structured JSON with:
  - Name, Age, Gender
  - Chief Complaint
  - Symptoms & Duration
  - Medical History
  - Medications
  - Allergies
  - Lifestyle
  - Original & Translated Text
```

**AI Prompt:**
```
You are a medical intake assistant. Extract patient information from this transcript and translate everything to English.

TRANSCRIPT (may be in Hindi, English, or other languages):
"à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® à¤°à¤¾à¤œ à¤¹à¥ˆ, à¤®à¥à¤à¥‡ à¤¬à¥à¤–à¤¾à¤° à¤¹à¥ˆ à¤¤à¥€à¤¨ à¤¦à¤¿à¤¨ à¤¸à¥‡"

Extract and translate the following information to English:
1. Full Name
2. Age
3. Gender
4. Chief Complaint (main problem/symptoms)
5. Duration of symptoms
...

Return as JSON: { ... }
```

**AI Response:**
```json
{
  "full_name": "Raj",
  "age": null,
  "gender": "male",
  "chief_complaint": "Fever",
  "symptom_duration": "3 days",
  "medical_history": [],
  "current_medications": [],
  "allergies": [],
  "previous_surgeries": [],
  "family_history": null,
  "lifestyle": {
    "smoking": "unknown",
    "alcohol": "unknown",
    "exercise": "unknown"
  },
  "additional_notes": null,
  "original_language": "Hindi",
  "original_transcript": "à¤®à¥‡à¤°à¤¾ à¤¨à¤¾à¤® à¤°à¤¾à¤œ à¤¹à¥ˆ, à¤®à¥à¤à¥‡ à¤¬à¥à¤–à¤¾à¤° à¤¹à¥ˆ à¤¤à¥€à¤¨ à¤¦à¤¿à¤¨ à¤¸à¥‡",
  "english_transcript": "My name is Raj, I have fever for three days"
}
```

### Step 7: Backend Returns Extracted Data
```
Add metadata:
  - processed_at: timestamp
  - patient_id: UUID
  - audio_language_code: "hi-IN"
â†“
Return JSON response to frontend
```

**HTTP Response:**
```json
{
  "success": true,
  "data": {
    "full_name": "Raj",
    "age": null,
    "gender": "male",
    "chief_complaint": "Fever",
    "symptom_duration": "3 days",
    ...
    "processed_at": "2024-01-15T10:30:00",
    "patient_id": "123e4567-e89b-12d3-a456-426614174000",
    "audio_language_code": "hi-IN"
  },
  "message": "Voice intake processed successfully"
}
```

### Step 8: Frontend Displays Extracted Data
```
Receive response
â†“
setExtractedData(result.data)
â†“
Show green card with extracted information:
  - Basic Info (Name, Age, Gender)
  - Chief Complaint
  - Medical History (badges)
  - Medications (badges)
  - Allergies (red badges)
  - Lifestyle (grid)
  - Transcripts (collapsible)
â†“
Show "Save to Profile" button
```

**UI Components:**
- Green success card
- Badges for medications, allergies, history
- Collapsible transcript viewer
- Save and "Record Again" buttons

### Step 9: Patient Saves to Profile
```
Click "Save to Profile"
â†“
Create FormData with:
  - patient_id: UUID
  - intake_data: JSON string of extracted data
â†“
POST /api/voice-intake/save-intake
```

**HTTP Request:**
```http
POST http://localhost:8000/api/voice-intake/save-intake
Content-Type: multipart/form-data

patient_id: "123e4567-e89b-12d3-a456-426614174000"
intake_data: "{\"full_name\":\"Raj\",\"age\":null,...}"
```

### Step 10: Backend Saves to Database âš ï¸ (FAILS IF TABLE DOESN'T EXIST)
```
Parse intake_data JSON
â†“
Create intake_record object:
  - patient_id
  - intake_data (full JSON)
  - created_at
  - full_name (extracted)
  - age (extracted)
  - chief_complaint (extracted)
  - symptom_duration (extracted)
  - medical_history (extracted)
  - current_medications (extracted)
  - allergies (extracted)
  - language_code (extracted)
â†“
Insert into voice_intake_records table
â†“
Return success response
```

**Database Insert:**
```python
# backend/app/voice_intake.py

intake_record = {
    'patient_id': patient_id,
    'intake_data': data,  # Full JSON
    'created_at': datetime.now().isoformat(),
    'full_name': data.get('full_name'),
    'age': data.get('age'),
    'chief_complaint': data.get('chief_complaint'),
    'symptom_duration': data.get('symptom_duration'),
    'medical_history': data.get('medical_history'),
    'current_medications': data.get('current_medications'),
    'allergies': data.get('allergies'),
    'language_code': data.get('audio_language_code', 'unknown')
}

result = supabase.table('voice_intake_records').insert(intake_record).execute()
```

**âŒ ERROR IF TABLE DOESN'T EXIST:**
```
Failed to save to database: relation "voice_intake_records" does not exist
```

### Step 11: Frontend Shows Success Message
```
Receive success response
â†“
Show toast notification:
  "Medical information saved successfully!"
  "View your saved records in History"
â†“
Provide "View History" button
```

### Step 12: Patient Views History
```
Click "View History" or navigate to /patient/voice-intake-history
â†“
Frontend fetches all records:
  GET from Supabase: voice_intake_records table
  WHERE patient_id = current_user_id
  ORDER BY created_at DESC
â†“
Display cards for each record:
  - Name
  - Date
  - Chief Complaint
  - Medications, Allergies
  - Expandable full details
```

**Database Query:**
```typescript
// frontend/app/patient/voice-intake-history/page.tsx

const { data: records } = await supabase
  .from('voice_intake_records')
  .select('*')
  .eq('patient_id', session.user.id)
  .order('created_at', { ascending: false })
```

## ğŸ—„ï¸ Database Schema

### voice_intake_records Table
```sql
CREATE TABLE voice_intake_records (
    id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
    patient_id UUID NOT NULL,
    intake_data JSONB NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    -- Extracted fields for easy querying
    full_name TEXT,
    age INTEGER,
    chief_complaint TEXT,
    symptom_duration TEXT,
    medical_history JSONB,
    current_medications JSONB,
    allergies JSONB,
    language_code TEXT,
    
    -- Foreign key
    CONSTRAINT fk_patient FOREIGN KEY (patient_id) 
        REFERENCES auth.users(id) ON DELETE CASCADE
);

-- Indexes
CREATE INDEX idx_voice_intake_patient_id ON voice_intake_records(patient_id);
CREATE INDEX idx_voice_intake_created_at ON voice_intake_records(created_at DESC);
```

### Row Level Security (RLS) Policies
```sql
-- Patients can view their own records
CREATE POLICY "Patients can view own voice intake records"
    ON voice_intake_records FOR SELECT
    USING (auth.uid() = patient_id);

-- Patients can insert their own records
CREATE POLICY "Patients can insert own voice intake records"
    ON voice_intake_records FOR INSERT
    WITH CHECK (auth.uid() = patient_id);

-- Doctors can view all records
CREATE POLICY "Doctors can view all voice intake records"
    ON voice_intake_records FOR SELECT
    USING (
        EXISTS (
            SELECT 1 FROM auth.users
            WHERE auth.users.id = auth.uid()
            AND auth.users.raw_user_meta_data->>'role' = 'doctor'
        )
    );

-- Service role has full access (for backend API)
CREATE POLICY "Service role has full access"
    ON voice_intake_records FOR ALL
    USING (auth.jwt()->>'role' = 'service_role');
```

## ğŸ”§ Why History Is Not Saving

### Root Cause
The `voice_intake_records` table **does not exist** in your Supabase database.

### Evidence
1. Backend logs show: `Failed to save to database: relation "voice_intake_records" does not exist`
2. The SQL script `SETUP_VOICE_INTAKE_COMPLETE.sql` exists but hasn't been run
3. Frontend can extract data but can't save it

### Solution
Run the SQL script in Supabase SQL Editor:

1. Go to https://supabase.com/dashboard
2. Select your project
3. Click "SQL Editor" in left sidebar
4. Click "New Query"
5. Copy entire contents of `SETUP_VOICE_INTAKE_COMPLETE.sql`
6. Paste and click "Run"
7. Verify success messages

## ğŸ“ File Structure

```
Vibeathon/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app/
â”‚       â”œâ”€â”€ main.py                    # FastAPI app (includes voice_intake router)
â”‚       â””â”€â”€ voice_intake.py            # Voice intake API endpoints
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ patient/
â”‚   â”‚       â”œâ”€â”€ dashboard/
â”‚   â”‚       â”‚   â””â”€â”€ page.tsx           # Dashboard with Voice Intake card
â”‚   â”‚       â”œâ”€â”€ voice-intake/
â”‚   â”‚       â”‚   â””â”€â”€ page.tsx           # Voice intake page
â”‚   â”‚       â””â”€â”€ voice-intake-history/
â”‚   â”‚           â””â”€â”€ page.tsx           # History page
â”‚   â””â”€â”€ components/
â”‚       â”œâ”€â”€ voice-intake/
â”‚       â”‚   â””â”€â”€ voice-intake-form.tsx  # Main form component
â”‚       â””â”€â”€ doctor/
â”‚           â””â”€â”€ patient-voice-intake-view.tsx  # Doctor view
â”‚
â””â”€â”€ SETUP_VOICE_INTAKE_COMPLETE.sql    # Database setup script
```

## ğŸ¯ Key Technologies

1. **Frontend Audio Capture**: MediaRecorder API (WebM/Opus)
2. **Speech-to-Text**: Google Cloud Speech-to-Text API
3. **AI Extraction**: Google Gemini 2.0 Flash
4. **Database**: Supabase (PostgreSQL)
5. **Backend**: FastAPI (Python)
6. **Frontend**: Next.js 14 (React, TypeScript)

## âœ… Testing Checklist

- [ ] Run SQL script in Supabase
- [ ] Restart backend server
- [ ] Navigate to /patient/voice-intake
- [ ] Select language
- [ ] Record 15-30 seconds of audio
- [ ] Verify extracted data displays
- [ ] Click "Save to Profile"
- [ ] Check for success toast
- [ ] Navigate to /patient/voice-intake-history
- [ ] Verify record appears in history
- [ ] Check Supabase table has data

## ğŸš¨ Common Issues

### 1. "No speech detected"
- **Cause**: Audio too short or silent
- **Fix**: Speak louder, record longer (15+ seconds)

### 2. "Failed to save to database"
- **Cause**: Table doesn't exist
- **Fix**: Run SQL script in Supabase

### 3. "GEMINI_API_KEY not configured"
- **Cause**: Missing API key in backend/.env
- **Fix**: Add `GEMINI_API_KEY=your_key_here`

### 4. "Google Cloud Speech credentials not configured"
- **Cause**: Missing Google Cloud credentials
- **Fix**: Set up Application Default Credentials

### 5. History page shows "No records"
- **Cause**: Table doesn't exist or RLS blocking access
- **Fix**: Run SQL script, check RLS policies

## ğŸ“Š Data Flow Summary

```
Audio (WebM) 
  â†’ Google Speech-to-Text 
  â†’ Text Transcript 
  â†’ Gemini AI 
  â†’ Structured JSON 
  â†’ Supabase Database 
  â†’ History Page
```

## ğŸ‰ Benefits

### For Patients
- âœ… Speak naturally in any language
- âœ… No typing required
- âœ… Faster than filling forms
- âœ… AI extracts everything automatically
- âœ… Review before saving

### For Doctors
- âœ… Complete patient history before consultation
- âœ… Critical info highlighted (allergies in red)
- âœ… Better prepared for video calls
- âœ… Time saved during appointments
- âœ… Multilingual support

## ğŸ” Security & Privacy

- âœ… Row Level Security (RLS) enabled
- âœ… Patients can only see their own records
- âœ… Doctors can see all records (for consultations)
- âœ… Service role has full access (for backend API)
- âœ… Audio not stored (only transcripts)
- âœ… HIPAA-compliant data handling

## ğŸ“ˆ Future Enhancements

- [ ] Real-time transcription during recording
- [ ] Edit extracted data before saving
- [ ] Share specific records with doctors
- [ ] Export as PDF
- [ ] Voice commands for navigation
- [ ] Offline support
- [ ] Multi-speaker detection
